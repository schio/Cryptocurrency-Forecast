{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 암호화폐 가격 예측\n",
    "\n",
    "Binance Market Data(CandleStick)와 Sequence2Sequence를 이용한 암호화폐 가격 예측.\n",
    "\n",
    "**TEST CASE**\n",
    "\n",
    "- Feature에 따른 Test\n",
    "\n",
    "- Layer에 따른 Test\n",
    "\n",
    "**무엇을 예측할 것인가**\n",
    "무엇을 예측할지도 중요한 포인트이다.\n",
    "\n",
    "- 미래 가격 그래프 예측\n",
    "\n",
    "- 최종 가격보다 n% 상승 혹은 하락 예측\n",
    "\n",
    "    - X시간 내에 n%상승 혹은 하락할 것인가\n",
    "    - X시간 후 Y시간 내에 n% 상승 혹은 하락할 것인가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is\t 3.5.6 |Anaconda, Inc.|\n",
      "Tensorflow version is\t 1.12.0\n",
      "GPU device is\t\t ['/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "print('Python version is\\t',sys.version.split()[0],sys.version.split()[1],sys.version.split()[2])\n",
    "print('Tensorflow version is\\t',tf.__version__)\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "print(\"GPU device is\\t\\t\",get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version is 3.5.6 |Anaconda, Inc.|\n",
      "tensorflow version is 1.12.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint as p\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from binance.client import Client\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def __Api__():\n",
    "    f = open(\"/home/scio/zepl/conf/API_KEY\", 'r')\n",
    "    line = f.readline()\n",
    "    f.close()\n",
    "    return line\n",
    "def __Sign__():\n",
    "    f = open(\"/home/scio/zepl/conf/SECRET_KEY\", 'r')\n",
    "    line = f.readline()\n",
    "    f.close()\n",
    "    return line\n",
    "    \n",
    "print('python version is',sys.version.split()[0],sys.version.split()[1],sys.version.split()[2])\n",
    "print('tensorflow version is',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API를 이용한 Kline(CandleSticks) 호출 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is (2702, 12)\n"
     ]
    }
   ],
   "source": [
    "BTC='BTCUSDT'\n",
    "client = Client(__Api__(),__Sign__())\n",
    "klines_orig = client.get_historical_klines(BTC, '4h', \"1 Jul, 2014\")\n",
    "\n",
    "for i in range(len(klines_orig)):\n",
    "    klines_orig[i][0]=int(datetime.fromtimestamp(klines_orig[i][0]/1000).strftime('%Y%m%d%H%M'))\n",
    "    klines_orig[i][6]=int(datetime.fromtimestamp(klines_orig[i][6]/1000).strftime('%Y%m%d%H%M'))\n",
    "klines=np.array(klines_orig)\n",
    "\n",
    "\n",
    "df=pd.DataFrame(klines)\n",
    "# To JSON\n",
    "with open(\"/home/scio/zepl/data/bitcoinKlines/4klines.json\", 'w') as f:\n",
    "    f.write(df.to_json(orient='records', lines=True))\n",
    "    \n",
    "# To CSV\n",
    "df.to_csv(\"/home/scio/zepl/data/bitcoinKlines/data4klines.csv\",sep=',')\n",
    "print(\"shape is\",klines.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현재 dataLoad의 return은 7가지 피쳐(OHLC, QuoteAssetVolume, NumOfTrades)만을 리턴하고있다.\n",
    "전체 피쳐를 리턴하여 트레이닝 할 경우 loss가 nan이 나온다. normalization의 문제로 추정 中\n",
    "\n",
    "### Data 로드 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoad(filename):\n",
    "    fp = open(filename, 'r')\n",
    "    csv_reader = csv.reader(fp)\n",
    "    btcusdt_data = []\n",
    "    for row in csv_reader:\n",
    "        btcusdt_data.append(row)\n",
    "    del btcusdt_data[0] #인덱스 역할 컬럼 제거\n",
    "    \n",
    "    \n",
    "    for row in btcusdt_data: #Open time\n",
    "        del row[0] # Open time\n",
    "        del row[6] # Close time 제거\n",
    "    dataset = []\n",
    "    for data in btcusdt_data:\n",
    "        data_point = []\n",
    "        is_null = False\n",
    "        for element in data[1:]:\n",
    "            if element == 'null':\n",
    "                is_null = True\n",
    "            else:\n",
    "                data_point.append(float(element))\n",
    "        if is_null:\n",
    "            continue\n",
    "        dataset.append(np.array(data_point))\n",
    "    dataset = np.array(dataset)\n",
    "    temp= np.array(dataset)\n",
    "\n",
    "    return dataset [:,0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSlicer(dataset):\n",
    "    seg_start = 0\n",
    "    seg_end = 100 #시계열 사이즈 셋팅 \n",
    "    train_size=1500 #트레인으로 몇개 쓸 지\n",
    "    num_of_pred=30 #캔들 몇개 예측할 지 \n",
    "    inputs = []\n",
    "    labels = []\n",
    "    while seg_end + num_of_pred <= len(dataset):\n",
    "        input_segment = dataset[seg_start:seg_end]\n",
    "        label_segment = dataset[seg_end:seg_end+num_of_pred]\n",
    "        inputs.append(input_segment)\n",
    "        labels.append(label_segment)\n",
    "        seg_start += 1\n",
    "        seg_end += 1\n",
    "    inputs = np.array(inputs)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    train_input = inputs[:train_size]\n",
    "    train_label = labels[:train_size]\n",
    "\n",
    "    test_input = inputs[train_size:]\n",
    "    test_label = labels[train_size:]\n",
    "\n",
    "    return train_input, train_label, test_input, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "   dataset = dataLoad(\"/home/scio/Desktop/bot/data/4klines.csv\")\n",
    "   train_input, train_label, test_input, test_label = timeSlicer(dataset)\n",
    "   return train_input, train_label, test_input, test_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format\n",
    "\n",
    "Candle Stick Data Format은 아래와 같다.\n",
    "원본 데이터의 칼럼 중 OpenTime, CloseTime, TakerBuyBaseAssetVolume, TakeBuyQuoteAssetVolum, Ignore은 제외하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Candle Sticks is (2691, 7)\n",
      "Type of Candle Sticks is <class 'numpy.ndarray'>\n",
      "      Open     High      Low    Close      Volume  QuoteAssetVolume  \\\n",
      "0  4261.48  4349.99  4261.32  4349.99   82.088865      3.531943e+05   \n",
      "1  4333.32  4485.39  4333.32  4427.30   63.619882      2.825012e+05   \n",
      "2  4436.06  4485.39  4333.42  4352.34  174.562001      7.742388e+05   \n",
      "3  4352.33  4354.84  4200.74  4325.23  225.109716      9.652911e+05   \n",
      "4  4307.56  4369.69  4258.56  4285.08  249.769913      1.079545e+06   \n",
      "\n",
      "   NumOfTrades  \n",
      "0        334.0  \n",
      "1        248.0  \n",
      "2        858.0  \n",
      "3        986.0  \n",
      "4       1001.0  \n"
     ]
    }
   ],
   "source": [
    "dataset = dataLoad(\"/home/scio/Desktop/bot/data/4klines.csv\")\n",
    "print(\"Shape of Candle Sticks is\",np.shape(dataset))\n",
    "print(\"Type of Candle Sticks is\",type(dataset))\n",
    "df = pd.DataFrame(dataset).rename(columns={0:'Open',1:'High',2:'Low',3:'Close',4:'Volume',5:'QuoteAssetVolume',6:'NumOfTrades',7:'TakerBuyBaseAssetVolume',8:'TakeBuyQuoteAssetVolum',9:'Ignore'})\n",
    "p(df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq 네트워크 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(inputs_ph, init_state, seq_len, out_seq_len, sizeOfColumns):\n",
    "   '''\n",
    "   arguments:\n",
    "      inputs_ph: input placeholder\n",
    "      init_state: 초기 상태 placeholder\n",
    "      seq_len: input의 time 길이\n",
    "      out_seq_len: output의 time 길이\n",
    "   return:\n",
    "      softmax result\n",
    "   '''\n",
    "   with tf.variable_scope('rnn') as scope:\n",
    "      # encoder\n",
    "      rc1 = init_state\n",
    "      for i in range(seq_len):\n",
    "         input_prev = tf.concat([inputs_ph[i], rc1], 1)\n",
    "         rc1 = fully_connected_layer(input_prev, NODE_NUM, 'rc1')\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         logits = fully_connected_layer(rc1, sizeOfColumns, 'logits')\n",
    "         if i==0:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "      # decoder\n",
    "      logits_list = [tf.reshape(logits, (-1, 1, sizeOfColumns))]\n",
    "      for i in range(out_seq_len-1):\n",
    "         input_prev = tf.concat([logits, rc1], 1)\n",
    "         rc1 = fully_connected_layer(input_prev, NODE_NUM, 'rc1')\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         rc1 = tf.nn.tanh(rc1)\n",
    "         logits = fully_connected_layer(rc1, sizeOfColumns, 'logits')\n",
    "         logits_list.append(tf.reshape(logits, (-1, 1, sizeOfColumns)))\n",
    "\n",
    "      result = tf.concat(logits_list, axis=1)\n",
    "\n",
    "   return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected_layer(input_tensor, out_node_num, name):\n",
    "   input_dim = input_tensor.shape.as_list()\n",
    "   W = tf.get_variable(name=name+'_weights', shape=[input_dim[1], out_node_num])\n",
    "   b = tf.get_variable(name=name+'_biases', shape=[out_node_num])\n",
    "   result = tf.matmul(input_tensor, W) + b\n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least Square Method을 이용한 Loss 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_graph(prediction, labels):\n",
    "   lsm = tf.reduce_mean(tf.reduce_sum(tf.square(prediction - labels), [1, 2]))\n",
    "   return lsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_NUM = 512\n",
    "SEQ_LEN = 100 #시계열 사이즈 셋팅\n",
    "OUT_SEQ_LEN = 30 #캔들 몇개 예측할지\n",
    "train_input, train_label, test_input, test_label = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizeOfColumns = np.shape(train_input)[2] #피쳐 갯수\n",
    "inputs = tf.placeholder(tf.float32, [None, SEQ_LEN, sizeOfColumns])\n",
    "\n",
    "inputs_max = tf.reduce_max(inputs, 1, True)\n",
    "inputs_min = tf.reduce_min(inputs, 1, True)\n",
    "normed_inputs = (inputs - inputs_min) / (inputs_max - inputs_min)\n",
    "\n",
    "inputs_t = tf.transpose(normed_inputs, [1, 0, 2])\n",
    "inputs_r = tf.reshape(inputs_t, [-1, sizeOfColumns])\n",
    "\n",
    "inputs_s = tf.split(inputs_r, SEQ_LEN, axis=0)\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [None, NODE_NUM])\n",
    "labels = tf.placeholder(tf.float32, [None, OUT_SEQ_LEN, sizeOfColumns])\n",
    "sizeOfColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn/rc1_weights:0\n",
      "rnn/rc1_biases:0\n",
      "rnn/logits_weights:0\n",
      "rnn/logits_biases:0\n"
     ]
    }
   ],
   "source": [
    "normed_labels = (labels - inputs_min) / (inputs_max - inputs_min)\n",
    "\n",
    "prediction = model(inputs_s, init_state, SEQ_LEN, OUT_SEQ_LEN, sizeOfColumns)\n",
    "loss = objective_graph(prediction, normed_labels)\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "for var in train_vars:\n",
    "   print(var.name)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 트레이닝을 진행한다.\n",
    "1. 1차로 Loss가 0.15 이하로 나올시 모델과 Loss값을 저장한다.\n",
    "2. 저장된 Loss값 * 0.9보다 낮은 Loss가 나올 시 다시 모델과 Loss값을 저장한다.\n",
    "\n",
    "2를 반복한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=700000\n",
    "\n",
    "filename=str(r)+'_'+str(SEQ_LEN)+'_'+str(OUT_SEQ_LEN)\n",
    "now=datetime.now()\n",
    "time=str(now.year)+str(now.month)+str(now.day)+'_'+str(now.hour)+str(now.minute)+'__'\n",
    "path=\"/home/scio/zepl/tensor/bitcoinPred/model/\"+time+filename+'/'\n",
    "os.system('mkdir '+path)\n",
    "print(path)\n",
    "\n",
    "lsm_scalar = tf.summary.scalar(filename,loss) #tensorboard loss\n",
    "summary=tf.summary.merge_all() #tensorboard\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "minLoss=0.15\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as sess:\n",
    "    with tf.device('/gpu:0'):\n",
    "        sess.run(init_op)\n",
    "        writer = tf.summary.FileWriter(\"/home/scio/zepl/tensor/bitcoinPred/board/\",sess.graph) #tensorboard\n",
    "        \n",
    "        with tf.name_scope('train'):\n",
    "            for step in range(r):\n",
    "            \n",
    "                shuffle_index = np.random.permutation(len(train_input))\n",
    "                batch_xs = train_input[shuffle_index[:100]]\n",
    "                batch_ys = train_label[shuffle_index[:100]]\n",
    "                feed_dict = {}\n",
    "                feed_dict[inputs] = batch_xs\n",
    "                feed_dict[labels] = batch_ys\n",
    "\n",
    "                init_state_value = np.zeros([len(batch_ys), NODE_NUM])\n",
    "                feed_dict[init_state] = init_state_value\n",
    "                sess.run(train_op, feed_dict=feed_dict)\n",
    "                \n",
    "                input_value = sess.run(normed_inputs, feed_dict=feed_dict)\n",
    "                label_value = sess.run(normed_labels, feed_dict=feed_dict)\n",
    "                pred_value = sess.run(prediction, feed_dict=feed_dict)\n",
    "                loss_value = sess.run(loss, feed_dict=feed_dict)\n",
    "                \n",
    "                # 이전의 Min Loss * 0.9 보다 낮은 Loss가 나올 경우 모델 저장\n",
    "                if (minLoss*0.9) > loss_value:\n",
    "                    minLoss=loss_value\n",
    "                    print(\"--------------------------------------------------\")\n",
    "                    print(step,'step train loss value: ', loss_value)\n",
    "                    saver.save(sess, path+str(loss_value))\n",
    "                show_loss = sess.run(lsm_scalar, feed_dict=feed_dict) #tensorboard loss\n",
    "                writer.add_summary(show_loss, step) #tensorboard loss\n",
    "        saver.save(sess, path+\"_final\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습된 모델을 이용하여 실제 테스트 후 이미지로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"mkdir \"+path+\"predImg\")\n",
    "for i in range(len(test_label)):\n",
    "\tplt.cla()\n",
    "\tplt.plot(range(-99, 1), input_value[i, :, 1], 'b')\n",
    "\tplt.plot(range(1, 31), label_value[i, :, 1], 'g')\n",
    "\tplt.plot(range(1, 31), pred_value[i, :, 1], 'r--')\n",
    "\tplt.title('test')\n",
    "\tplt.savefig(path+\"predImg/test\"+str(i)+\".png\")\n",
    "\t\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
